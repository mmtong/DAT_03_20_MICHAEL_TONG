{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "In this project, you will implement the exploratory analysis plan developed in Project 1. This will lay the groundwork for our our first modeling exercise in Project 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the python libraries you will need for this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read in your data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "#Read in data from source \n",
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "print df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "#### Question 1. How many observations are in our dataset? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       400\n",
       "gre         398\n",
       "gpa         398\n",
       "prestige    399\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. Create a summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>2.486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa    prestige\n",
       "count  400.000000  398.000000  398.00000  399.000000\n",
       "mean     0.317500  588.040201    3.39093    2.486216\n",
       "std      0.466087  115.628513    0.38063    0.945333\n",
       "min      0.000000  220.000000    2.26000    1.000000\n",
       "25%      0.000000  520.000000    3.13000    2.000000\n",
       "50%      0.000000  580.000000    3.39500    2.000000\n",
       "75%      1.000000  660.000000    3.67000    3.000000\n",
       "max      1.000000  800.000000    4.00000    4.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. Why would GRE have a larger STD than GPA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The range of GRE is much large than GPA it goes from 220 to 800, while the range for GPA is only from 2.26 to 4.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 4. Drop data points with missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       0\n",
       "gre         2\n",
       "gpa         2\n",
       "prestige    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige\n",
       "0        0  380.0  3.61       3.0\n",
       "1        1  660.0  3.67       3.0\n",
       "2        1  800.0  4.00       1.0\n",
       "3        1  640.0  3.19       4.0\n",
       "4        0  520.0  2.93       4.0\n",
       "5        1  760.0  3.00       2.0\n",
       "6        1  560.0  2.98       1.0\n",
       "7        0  400.0  3.08       2.0\n",
       "8        1  540.0  3.39       3.0\n",
       "9        0  700.0  3.92       2.0\n",
       "10       0  800.0  4.00       4.0\n",
       "11       0  440.0  3.22       1.0\n",
       "12       1  760.0  4.00       1.0\n",
       "13       0  700.0  3.08       2.0\n",
       "14       1  700.0  4.00       1.0\n",
       "15       0  480.0  3.44       3.0\n",
       "16       0  780.0  3.87       4.0\n",
       "17       0  360.0  2.56       3.0\n",
       "18       0  800.0  3.75       2.0\n",
       "19       1  540.0  3.81       1.0\n",
       "20       0  500.0  3.17       3.0\n",
       "21       1  660.0  3.63       2.0\n",
       "22       0  600.0  2.82       4.0\n",
       "23       0  680.0  3.19       4.0\n",
       "24       1  760.0  3.35       2.0\n",
       "25       1  800.0  3.66       1.0\n",
       "26       1  620.0  3.61       1.0\n",
       "27       1  520.0  3.74       4.0\n",
       "28       1  780.0  3.22       2.0\n",
       "29       0  520.0  3.29       1.0\n",
       "..     ...    ...   ...       ...\n",
       "370      1  540.0  3.77       2.0\n",
       "371      1  680.0  3.76       3.0\n",
       "372      1  680.0  2.42       1.0\n",
       "373      1  620.0  3.37       1.0\n",
       "374      0  560.0  3.78       2.0\n",
       "375      0  560.0  3.49       4.0\n",
       "376      0  620.0  3.63       2.0\n",
       "377      1  800.0  4.00       2.0\n",
       "378      0  640.0  3.12       3.0\n",
       "379      0  540.0  2.70       2.0\n",
       "380      0  700.0  3.65       2.0\n",
       "381      1  540.0  3.49       2.0\n",
       "382      0  540.0  3.51       2.0\n",
       "383      0  660.0  4.00       1.0\n",
       "384      1  480.0  2.62       2.0\n",
       "385      0  420.0  3.02       1.0\n",
       "386      1  740.0  3.86       2.0\n",
       "387      0  580.0  3.36       2.0\n",
       "388      0  640.0  3.17       2.0\n",
       "389      0  640.0  3.51       2.0\n",
       "390      1  800.0  3.05       2.0\n",
       "391      1  660.0  3.88       2.0\n",
       "392      1  600.0  3.38       3.0\n",
       "393      1  620.0  3.75       2.0\n",
       "394      1  460.0  3.99       3.0\n",
       "395      0  620.0  4.00       2.0\n",
       "396      0  560.0  3.04       3.0\n",
       "397      0  460.0  2.63       2.0\n",
       "398      0  700.0  3.65       2.0\n",
       "399      0  600.0  3.89       3.0\n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       0\n",
       "gre         2\n",
       "gpa         2\n",
       "prestige    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 5. Confirm that you dropped the correct data. How can you tell? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6. Create box plots for GRE and GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11128ed50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISBJHWYISFKH/T/KsunDciR6agAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111246390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#boxplot 1\n",
    "df_raw['gre'].plot(kind='box',ylim=(100,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111360890>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11138a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#boxplot 2 \n",
    "df_raw['gpa'].plot(kind='box',ylim=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7. What do this plots show?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The plots shows min, max, mean, median, and the quartile and interquartile range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8. Describe each distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115f6f7d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEclz/x9+QKj7/nK7BwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c2df10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, sharey=False)\n",
    "df_raw.plot(kind='hist', x='admit', y='gre',ax=axs[0])\n",
    "df_raw.plot(kind='hist', x='admit', y='gpa', ax=axs[1])\n",
    "df_raw.plot(kind='hist', x='admit', y='prestige', ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9.  If our model had an assumption of a normal distribution would we meet that requirement? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: If residuals are less than zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10.  Does this distribution need correction? If so, why? How? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Could normalize the GRE dataset so the data does not over influence the GPA and Prestige"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11. Which of our variables are potentially colinear? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182919</td>\n",
       "      <td>0.175952</td>\n",
       "      <td>-0.241355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.182919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>-0.124533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.175952</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <td>-0.241355</td>\n",
       "      <td>-0.124533</td>\n",
       "      <td>-0.059031</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             admit       gre       gpa  prestige\n",
       "admit     1.000000  0.182919  0.175952 -0.241355\n",
       "gre       0.182919  1.000000  0.382408 -0.124533\n",
       "gpa       0.175952  0.382408  1.000000 -0.059031\n",
       "prestige -0.241355 -0.124533 -0.059031  1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a correlation matrix for the data\n",
    "df_raw.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12. What did you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: GRE has the highest correlation to admission. Presitge of undergraduate school has a negative correlation to admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13. Write an analysis plan for exploring the association between grad school admissions rates and prestige of  undergraduate schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>admit</td>      <th>  R-squared:         </th> <td>   0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 19 Apr 2017</td> <th>  Prob (F-statistic):</th> <td>1.07e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:51:26</td>     <th>  Log-Likelihood:    </th> <td> -248.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   399</td>      <th>  AIC:               </th> <td>   501.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   509.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.6112</td> <td>    0.064</td> <td>    9.585</td> <td> 0.000</td> <td>    0.486     0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige</th>  <td>   -0.1188</td> <td>    0.024</td> <td>   -4.955</td> <td> 0.000</td> <td>   -0.166    -0.072</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>277.527</td> <th>  Durbin-Watson:     </th> <td>   1.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  59.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.726</td>  <th>  Prob(JB):          </th> <td>1.33e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.793</td>  <th>  Cond. No.          </th> <td>    8.43</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   R-squared:                       0.058\n",
       "Model:                            OLS   Adj. R-squared:                  0.056\n",
       "Method:                 Least Squares   F-statistic:                     24.56\n",
       "Date:                Wed, 19 Apr 2017   Prob (F-statistic):           1.07e-06\n",
       "Time:                        20:51:26   Log-Likelihood:                -248.52\n",
       "No. Observations:                 399   AIC:                             501.0\n",
       "Df Residuals:                     397   BIC:                             509.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.6112      0.064      9.585      0.000         0.486     0.737\n",
       "prestige      -0.1188      0.024     -4.955      0.000        -0.166    -0.072\n",
       "==============================================================================\n",
       "Omnibus:                      277.527   Durbin-Watson:                   1.963\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               59.297\n",
       "Skew:                           0.726   Prob(JB):                     1.33e-13\n",
       "Kurtosis:                       1.793   Cond. No.                         8.43\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "x = smf.ols(formula='admit ~ prestige', data=df_raw).fit()\n",
    "\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>prestige</td>     <th>  R-squared:         </th> <td>   0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 19 Apr 2017</td> <th>  Prob (F-statistic):</th> <td>1.07e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:55:30</td>     <th>  Log-Likelihood:    </th> <td> -531.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   399</td>      <th>  AIC:               </th> <td>   1067.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.6410</td> <td>    0.056</td> <td>   47.507</td> <td> 0.000</td> <td>    2.532     2.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>admit</th>     <td>   -0.4902</td> <td>    0.099</td> <td>   -4.955</td> <td> 0.000</td> <td>   -0.685    -0.296</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>29.899</td> <th>  Durbin-Watson:     </th> <td>   1.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  11.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.116</td> <th>  Prob(JB):          </th> <td> 0.00356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.210</td> <th>  Cond. No.          </th> <td>    2.42</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               prestige   R-squared:                       0.058\n",
       "Model:                            OLS   Adj. R-squared:                  0.056\n",
       "Method:                 Least Squares   F-statistic:                     24.56\n",
       "Date:                Wed, 19 Apr 2017   Prob (F-statistic):           1.07e-06\n",
       "Time:                        20:55:30   Log-Likelihood:                -531.25\n",
       "No. Observations:                 399   AIC:                             1067.\n",
       "Df Residuals:                     397   BIC:                             1074.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.6410      0.056     47.507      0.000         2.532     2.750\n",
       "admit         -0.4902      0.099     -4.955      0.000        -0.685    -0.296\n",
       "==============================================================================\n",
       "Omnibus:                       29.899   Durbin-Watson:                   1.847\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               11.278\n",
       "Skew:                           0.116   Prob(JB):                      0.00356\n",
       "Kurtosis:                       2.210   Cond. No.                         2.42\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = smf.ols(formula='prestige ~ admit', data=df_raw).fit()\n",
    "y.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Run a OLS regression between admit and prestige using the statsmodel package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14. What is your hypothesis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There is very little correlation between presitge and admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Review Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is test error and train error?\n",
    "2. What are ways to mitigate a situation where you have low train error but high test error?\n",
    "3. What are some of the parameters you can tweak to get a better fit in ordinary linear regression?\n",
    "4. What package would you use to explore these parameters easily and find the best model?\n",
    "5. What is the difference between Lasso and Ridge regression?\n",
    "    6a. When do you use which?\n",
    "6. Bonus: Explore alternatives to dropping obervations with missing data\n",
    "\n",
    "Advanced Bonus:\n",
    "1. What makes Lasso regression do what it does to the coefficients?\n",
    "2. How do you deal with multi-colinearity when performing linear regression?\n",
    "3. What is the \"distance\" formula in KNN? I.e. how does KNN account for distance to the k neighbours when predicting the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
